{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Binary Classification\n",
    "\n",
    "Example of binary classification with an MLP\n",
    "\n",
    "Uses the UCI sonar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages\n",
    "\n",
    "Run the cell below to import the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [9, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Loading the dataset\n",
    "\n",
    "The UCI sonar dataset is a well studied dataset with previous studies producing accuracies in the range of 84% to 88%, which we set as an evaluation metric.\n",
    "\n",
    "The output label are strings with either \"M\" or \"R\". We need to one hot encode these into integers first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "R\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "absdir = os.path.dirname(os.path.realpath('__file__'))\n",
    "datapath = \"../data/sonar.csv\"\n",
    "\n",
    "dataframe = read_csv(os.path.join(absdir, datapath), header=None)\n",
    "dataset = dataframe.values\n",
    "\n",
    "X = dataset[:, 0:60].astype(float)\n",
    "print(X[0].shape)\n",
    "y = dataset[:, 60]\n",
    "print(y[0])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "print(encoded_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Building the model\n",
    "\n",
    "We can start by building a simple NN with the following structure:\n",
    "\n",
    "```\n",
    "Input (60) -> Hidden (60 units) -> Output (1 unit)\n",
    "```\n",
    "\n",
    "We use the `ReLU` activation function for the hidden units and the `sigmoid` activation for the output unit since its a binary classification problem.\n",
    "\n",
    "We optimize against the cost function `binary_crossentropy` and use the adam optimizer. We also collect the accuracy/loss metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Automatic KFold validation\n",
    "\n",
    "We perform 10 fold validation on training the dataset as it is a small dataset and will produce more accurate reports of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81818183 0.85714287 0.80952382 0.80952382 0.76190477 0.85714286\n",
      " 0.85714287 0.85       0.70000001 0.95      ]\n",
      "Mean Accuracy: 82.71 Std Dev: 6.28\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=base_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_y, cv=kfold)\n",
    "print(results)\n",
    "print(\"Mean Accuracy: {:.2f} Std Dev: {:.2f}\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Data Preparation\n",
    "\n",
    "Each of the input data is in a different scale. We can try to improve the model's performance through standardization which means each attribute has 0 mean with a standard deviation of 1.\n",
    "\n",
    "By standardizing the data, we help speed by training by using a larger learning rate since we center the data around its mean which results in a more well-formed shape of the data plot (\"circular\" or \"concentric\" plot) to perform gradient descent whereas without it, the data plot in higher dimensional plane will be an ellipsoid which means we need to slow down learning with a lower learning rate to reach convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81818183 1.         0.76190478 0.90476191 0.85714287 0.85714287\n",
      " 0.90476191 0.8        0.75000001 0.90000001]\n",
      "Mean Accuracy: 85.54 Std Dev: 7.22\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append((\"standardize\", StandardScaler()))\n",
    "estimators.append((\"mlp\", KerasClassifier(build_fn=base_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_y, cv=kfold)\n",
    "print(results)\n",
    "print(\"Mean Accuracy: {:.2f} Std Dev: {:.2f}\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Network architecture\n",
    "\n",
    "We can experiment with various network architectures to see if it improves model performance.\n",
    "\n",
    "We can try with a smaller network of the following topology:\n",
    "```\n",
    "Input (60) -> Hidden (30 units) -> Output (1 unit) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86363637 0.95238096 0.80952382 0.80952382 0.85714287 0.76190477\n",
      " 0.90476191 0.75       0.75000001 0.85000001]\n",
      "Smaller network: Mean accuracy: 83.09 Std Dev: 6.41\n"
     ]
    }
   ],
   "source": [
    "def smaller_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append((\"standardize\", StandardScaler()))\n",
    "estimators.append((\"mlp\", KerasClassifier(build_fn=smaller_network, epochs=100, batch_size=5, verbose=0)))\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_y, cv=kfold)\n",
    "print(results)\n",
    "print(\"Smaller network: Mean accuracy: {:.2f} Std Dev: {:.2f}\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try with evaluating a larger network of the following topology:\n",
    "\n",
    "```\n",
    "Input (60) -> Hidden (60) -> Hidden (30) -> Output (1 unit)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81818183 0.95238096 0.71428572 0.90476191 0.85714287 0.80952382\n",
      " 0.95238096 0.8        0.80000001 0.90000001]\n",
      "Larger network: Mean accuracy: 85.09 Std Dev: 7.25\n"
     ]
    }
   ],
   "source": [
    "def larger_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, activation=\"relu\"))\n",
    "    model.add(Dense(30, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append((\"standardize\", StandardScaler()))\n",
    "estimators.append((\"mlp\", KerasClassifier(build_fn=larger_network, epochs=100, batch_size=5, verbose=0)))\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_y, cv=kfold)\n",
    "print(results)\n",
    "print(\"Larger network: Mean accuracy: {:.2f} Std Dev: {:.2f}\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
